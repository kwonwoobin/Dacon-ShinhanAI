{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 경로 리스트 생성\n",
    "file_list = glob.glob(\"../../data/raw/KOBIS_박스오피스_영화정보/KC_KOBIS_BOX_OFFIC_MOVIE_INFO_*.csv\")\n",
    "\n",
    "# CSV 파일 데이터프레임으로 변환\n",
    "df_list = [pd.read_csv(file) for file in file_list]\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "m = pd.read_csv(\"../../data/raw/KOBIS_개봉일람.csv\", encoding=\"cp949\")\n",
    "\n",
    "# 데이터프레임을 세로로 연결\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "merged_df = merged_df.rename(columns={i:j for i, j in zip(merged_df.columns, m.columns)})\n",
    "m = m.rename(columns={i:j for i, j in zip(m.columns, merged_df.columns)})\n",
    "\n",
    "m = pd.concat([m, merged_df], ignore_index=True, axis=0)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전국 스크린수 컬럼에서 평균보다 큰 데이터만 선택\n",
    "m = m[m[\"전국 스크린수\"] > m[\"전국 스크린수\"].mean()]\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순번, 수입사, 서울 매출액, 서울 관객수 컬럼 삭제\n",
    "m = m.drop([\"순번\", \"수입사\", \"서울 매출액\", \"서울 관객수\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복된 행 제거\n",
    "m.drop_duplicates(subset=[\"영화명\", \"장르\", \"등급\", \"영화구분\"], keep=\"first\", inplace=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime 형식으로 변환하는 함수\n",
    "def format_date(date):\n",
    "    if isinstance(date, (int, float)):\n",
    "        date = str(int(date))\n",
    "    else:\n",
    "        date = str(date)\n",
    "    date = date.replace(\"-\", \"\").replace(\".\", \"\")[:8]\n",
    "    formatted_date = datetime.datetime.strptime(date[:6], \"%Y%m\")\n",
    "    return formatted_date.strftime(\"%Y-%m\")\n",
    "\n",
    "# apply 함수를 사용하여 format_date 함수를 적용\n",
    "m['개봉일'] = m['개봉일'].apply(format_date)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.drop([\"영화유형\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.drop([\"영화형태\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국적 컬럼의 빈도수가 높은 상위 10개 값 선택\n",
    "nation = \"|\".join(m[\"국적\"].value_counts().head(10).index)\n",
    "\n",
    "nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 10개 값이 아닌 값을 기타로 변경\n",
    "m.loc[~m[\"국적\"].str.contains(nation), \"국적\"] = \"기타\"\n",
    "\n",
    "# 변경 후 기타의 수\n",
    "etc_count = len(m[m[\"국적\"] == \"기타\"])\n",
    "\n",
    "# 변경후 상위 10개 값의 수\n",
    "top10_count = len(m[m[\"국적\"] != \"기타\"])\n",
    "\n",
    "# 상위 10개 값의 수와 합쳐서 총 수 확인\n",
    "print(\"전체 수:\", top10_count + etc_count, len(m))\n",
    "\n",
    "# 변경 후 고윳값 확인\n",
    "print(m[\"국적\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과를 기반으로 값 변경\n",
    "m.loc[m[\"등급\"] == \"청소년관람불가15세이상관람가\", \"등급\"] = \"15세이상관람가\"\n",
    "\n",
    "m[m[\"등급\"] == \"청소년관람불가15세이상관람가\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과를 기반으로 값 변경\n",
    "m.loc[m[\"등급\"] == \"12세관람가\", \"등급\"] = \"12세이상관람가\"\n",
    "\n",
    "m[m[\"등급\"] == \"12세관람가\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과를 기반으로 값 변경\n",
    "m.loc[m[\"등급\"] == \"15세관람가\", \"등급\"] = \"15세이상관람가\"\n",
    "\n",
    "m[m[\"등급\"] == \"15세관람가\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과를 기반으로 값 변경\n",
    "m.loc[m[\"등급\"] == \"12세이상관람가15세이상관람가\", \"등급\"] = \"12세이상관람가\"\n",
    "\n",
    "m[m[\"등급\"] == \"12세이상관람가15세이상관람가\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복된 행 제거\n",
    "m.drop_duplicates(subset=[\"영화명\", \"감독\"], keep=\"first\", inplace=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.to_csv(\"../../data/processed/processed_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_csv(\"../../data/processed/processed_1.csv\")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "감독 = m[m[\"감독\"].isna()][\"영화명\"].tolist()\n",
    "제작사 = m[m[\"제작사\"].isna()][\"영화명\"].tolist()\n",
    "배급사 = m[m[\"배급사\"].isna()][\"영화명\"].tolist()\n",
    "관객수 = m[m[\"전국 매출액\"].isna()][\"영화명\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_names = {}\n",
    "\n",
    "for title in tqdm(감독):\n",
    "    url = \"https://search.naver.com/search.naver?ie=UTF-8&query=\" + title + \" 감독\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    try:\n",
    "        director_name = soup.select_one(\"#mflick > div > div > ul > li > div > div.title_box > strong\").text\n",
    "        director_names[title] = director_name.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "director_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in director_names.items():\n",
    "    m.loc[m[\"영화명\"] == k, \"감독\"] = v\n",
    "    print(m.loc[m[\"영화명\"] == k][[\"영화명\", \"감독\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_company_list = {}\n",
    "\n",
    "for title in tqdm(제작사):\n",
    "    try:\n",
    "        url = \"https://ko.wikipedia.org/wiki/\" + title\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        # 제작사 정보가 있는 Infobox 테이블의 label 태그를 선택\n",
    "        infobox_label = soup.select(\".infobox-label\")\n",
    "\n",
    "        # 제작사라는 텍스트를 가진 label 태그의 자손 th 태그 선택\n",
    "        production_company_list[title] = \"\".join([label.find_next(\"a\").text for label in infobox_label if label.text == \"제작사\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in production_company_list.items():\n",
    "    if v != \"\":\n",
    "        m.loc[m[\"영화명\"] == k, \"제작사\"] = v\n",
    "        print(m.loc[m[\"영화명\"] == k][[\"영화명\", \"제작사\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "배급사_리스트 = [\"20세기 폭스 코리아\", \"UPI 코리아\", \"UPI 코리아\", \"UPI 코리아\", \"트리플픽쳐스\", \"인디플러그\", \"시네마리퍼블릭\"]\n",
    "\n",
    "for k, v in zip(배급사, 배급사_리스트):\n",
    "    m.loc[m[\"영화명\"] == k, \"배급사\"] = v\n",
    "    print(m.loc[m[\"영화명\"] == k][[\"영화명\", \"배급사\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "관객수_리스트 = [5274, 360873, 208739, 1966, 35210, 41049, 1100000]\n",
    "\n",
    "for k, v in zip(관객수, 관객수_리스트):\n",
    "    m.loc[m[\"영화명\"] == k, \"전국 관객수\"] = v\n",
    "    print(m.loc[m[\"영화명\"] == k][[\"영화명\", \"전국 관객수\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.to_csv(\"../../data/processed/processed_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_csv(\"../../data/processed/processed_2.csv\")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감독, 제작사 결측치 제거\n",
    "m = m.dropna(subset=[\"감독\", \"제작사\"]).reset_index(drop=True)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감독별 전국 관객수 평균값 계산\n",
    "director_groupby = m.groupby(\"감독\")[\"전국 관객수\"].apply(lambda x: x.sum().mean())\n",
    "# 제작사별 전국 관객수 평균값 계산\n",
    "producer_groupby = m.groupby(\"제작사\")[\"전국 관객수\"].apply(lambda x: x.sum().mean())\n",
    "# 배급사별 전국 관객수 평균값 계산\n",
    "distributor_groupby = m.groupby(\"배급사\")[\"전국 관객수\"].apply(lambda x: x.sum().mean())\n",
    "\n",
    "# 각 값을 변환\n",
    "m[\"감독\"] = m[\"감독\"].map(director_groupby)\n",
    "m[\"제작사\"] = m[\"제작사\"].map(producer_groupby)\n",
    "m[\"배급사\"] = m[\"배급사\"].map(distributor_groupby)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연월 분리\n",
    "m['개봉년'] = m['개봉일'].apply(lambda x: int(x.split('-')[0]))\n",
    "m['개봉월'] = m['개봉일'].apply(lambda x: int(x.split('-')[1]))\n",
    "\n",
    "# 영화명, 개봉일, 전국 매출액 컬럼 삭제\n",
    "m = m.drop([\"영화명\", \"개봉일\", \"전국 매출액\"], axis=1)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 추출\n",
    "categorical_features = [\"국적\", \"장르\", \"등급\", \"영화구분\"]\n",
    "m_categorical = m[categorical_features]\n",
    "\n",
    "# 범주형 변수 OneHotEncoding\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "m_categorical_encoded = encoder.fit_transform(m_categorical)\n",
    "\n",
    "# OneHotEncoding 결과 데이터프레임으로 변환\n",
    "m_categorical_encoded_df = pd.DataFrame.sparse.from_spmatrix(m_categorical_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# 열 이름 바꾸기\n",
    "new_columns = [column.replace(\"x0_\", \"국적_\").replace(\"x1_\", \"장르_\").replace(\"x2_\", \"등급_\").replace(\"x3_\", \"영화구분_\") for column in m_categorical_encoded_df.columns]\n",
    "m_categorical_encoded_df.columns = new_columns\n",
    "\n",
    "# 인코딩 변수를 새로운 데이터프레임에 추가\n",
    "m_new = pd.concat([m.drop(categorical_features, axis=1), m_categorical_encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개봉월 컬럼 삭제\n",
    "m_new.drop([\"개봉월\"], axis=1, inplace=True)\n",
    "\n",
    "m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중공선선 확인\n",
    "X = m_new.iloc[:, :6]\n",
    "\n",
    "# 변수(features)와 VIF 값을 담을 데이터프레임 생성\n",
    "vif = pd.DataFrame()\n",
    "vif[\"features\"] = X.columns\n",
    "\n",
    "# X 데이터프레임의 각 변수에 대한 VIF 값을 계산하여 vif_factor 컬럼에 저장\n",
    "vif[\"vif_factor\"] = [variance_inflation_factor(X.values.astype(float), i) for i in range(X.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 행렬\n",
    "m_corr = X.corr()\n",
    "\n",
    "# 상관관계 행렬로부터 공분산행렬 구하기\n",
    "cov_matrix = np.linalg.inv(m_corr.values)\n",
    "\n",
    "# 공분산행렬에서 대각성분 계산\n",
    "eigenvalues = np.linalg.eigvals(cov_matrix)\n",
    "\n",
    "# 다중공선성 진단을 위한 조건수(condition number) 계산\n",
    "cond_num = np.max(eigenvalues) / np.min(eigenvalues)\n",
    "\n",
    "cond_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_new.to_csv(\"../../data/processed/processed_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, learning_curve, validation_curve\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import multiprocessing\n",
    "import optuna\n",
    "import cma\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_csv(\"../../data/processed/processed_3.csv\")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_feature_elimination(X, y, model, min_features=1, verbose=True):\n",
    "    # 초기 변수 개수\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # 현재 변수들의 성능\n",
    "    best_score = float(\"inf\")\n",
    "    best_features = X.columns.tolist()\n",
    "    \n",
    "    # 최소 변수 개수 이상인 경우\n",
    "    while n_features > min_features:\n",
    "        # 모든 변수에 대해 반복\n",
    "        scores = []\n",
    "        for feature in X.columns:\n",
    "            # 선택한 변수 제외\n",
    "            features = X.columns.drop(feature)\n",
    "            X_new = X[features]\n",
    "            \n",
    "            # 모델 학습 및 평가\n",
    "            model.fit(X_new, y)\n",
    "            y_pred = model.predict(X_new)\n",
    "            score = mean_squared_error(y, y_pred)\n",
    "            scores.append(score)\n",
    "            \n",
    "        # 가장 성능이 좋은 변수 선택\n",
    "        idx = pd.Index(scores).argmin()\n",
    "        worst_feature = X.columns[idx]\n",
    "        \n",
    "        # 변수 제거\n",
    "        X.drop(worst_feature, axis=1, inplace=True)\n",
    "        n_features = X.shape[1]\n",
    "        if verbose:\n",
    "            print(f\"Removing {worst_feature}: {n_features} features left\")\n",
    "        \n",
    "        # 모든 변수를 제거한 경우\n",
    "        if n_features == 0:\n",
    "            break\n",
    "        \n",
    "        # 현재 변수 개수에서의 성능이 최선인 경우\n",
    "        if min(scores) < best_score:\n",
    "            best_score = min(scores)\n",
    "            best_features = X.columns.tolist()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # 최종 선택된 변수들\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNetCV 모델 객체 생성\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "enet = ElasticNetCV(alphas=alphas, l1_ratio=0.5, cv=5, max_iter=10000)\n",
    "\n",
    "# 최소 변수 개수 지정\n",
    "min_features = 5\n",
    "\n",
    "# 재귀적 변수 제거 수행\n",
    "X = m.drop(\"전국 관객수\", axis=1)\n",
    "y = m[\"전국 관객수\"]\n",
    "selected_features = recursive_feature_elimination(X, y, enet, min_features=min_features)\n",
    "\n",
    "# 선택된 변수 출력\n",
    "print(f\"{len(selected_features)} features selected:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X = m[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor 모델 학습\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# RandomForestRegressor 모델 예측\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, rf_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X, y, cv=5, scoring=\"r2\"):\n",
    "    # 학습곡선 계산\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=cv, scoring=scoring,\n",
    "                                                            train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "    # 트레이닝, 크로스벨리데이션 평균 계산\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    # 학습곡선 시각화\n",
    "    plt.plot(train_sizes, train_mean, label=\"트레이닝 점수\")\n",
    "    plt.plot(train_sizes, test_mean, label=\"검증 점수\")\n",
    "    plt.title(f\"{type(model).__name__} 학습곡선\")\n",
    "    plt.xlabel(\"학습 데이터 수\")\n",
    "    plt.ylabel(\"성능 점수\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor 모델 학습\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# GradientBoostingRegressor 모델 예측\n",
    "gb_y_pred = gb.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, gb_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(gb, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressor 모델 학습\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# XGBRegressor 모델 예측\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, xgb_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, xgb_y_pred)\n",
    "r2 = r2_score(y_test, xgb_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(xgb, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMRegressor 모델 학습\n",
    "lgbm = LGBMRegressor(random_state=42)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# LGBMRegressor 모델 예측\n",
    "lgbm_y_pred = lgbm.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, lgbm_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, lgbm_y_pred)\n",
    "r2 = r2_score(y_test, lgbm_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(lgbm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTreesRegressor 모델 학습\n",
    "et = ExtraTreesRegressor(random_state=42)\n",
    "et.fit(X_train, y_train)\n",
    "\n",
    "# ExtraTreesRegressor 모델 예측\n",
    "et_y_pred = et.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, et_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, et_y_pred)\n",
    "r2 = r2_score(y_test, et_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(et, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 모델에서 예측한 결과값을 변수로 갖는 데이터프레임 생성\n",
    "pred_df = pd.DataFrame({\n",
    "        \"rf\": rf_y_pred,\n",
    "        \"gb\": gb_y_pred,\n",
    "        \"sgb\": xgb_y_pred,\n",
    "        \"lgbm\": lgbm_y_pred,\n",
    "        \"et\" : et_y_pred\n",
    "    })\n",
    "\n",
    "# 상관 행렬 계산\n",
    "corr_matrix = pred_df.corr()\n",
    "\n",
    "# 시각화\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타 모델 선정\n",
    "models = [rf, gb, xgb, lgbm, et]\n",
    "best_score = float(\"-inf\")\n",
    "best_model = None\n",
    "\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    rmse = (-1 * score.mean()) ** 0.5\n",
    "    if rmse > best_score:\n",
    "        best_score = rmse\n",
    "        best_model = model\n",
    "\n",
    "print(\"best_model :\", best_model)\n",
    "\n",
    "# 앙상블 모델 정의\n",
    "stack = StackingCVRegressor(regressors=(rf, gb, xgb, lgbm, et),\n",
    "                            meta_regressor=best_model,\n",
    "                            cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                            use_features_in_secondary=True)\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# 앙상블 모델 예측\n",
    "y_pred = stack.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(stack, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(model_objective, n_trials=100):\n",
    "    # Bayesian optimization 방식의 하이퍼파라미터 튜닝을 위해 Optuna 라이브러리 사용\n",
    "    # 최소화를 목적으로 하기 때문에 'minimize'로 설정\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.CmaEsSampler())\n",
    "    \n",
    "    # 사용 가능한 모든 CPU 코어 수를 사용하여 병렬 처리\n",
    "    n_jobs = multiprocessing.cpu_count()  \n",
    "    \n",
    "    # 모델 하이퍼파라미터 최적화 실행\n",
    "    study.optimize(model_objective, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    \n",
    "    # 최적 하이퍼파라미터와 그 때의 평가지표 출력\n",
    "    print(f\"Best RMSE: {study.best_value:.4f}\")\n",
    "    print(f\"Best Parameters: {study.best_params}\")\n",
    "    \n",
    "    # 최적 하이퍼파라미터 반환\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 모델의 하이퍼파라미터 탐색 공간과 목적 함수 정의\n",
    "def rf_objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=100)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    score = cross_val_score(rf, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    rmse = (-1 * score.mean()) ** 0.5\n",
    "    return rmse\n",
    "\n",
    "# Random Forest 모델의 하이퍼파라미터 최적화\n",
    "rf_params = optimize_model(rf_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼 파라미터 적용 후 학습 및 예측\n",
    "rf.set_params(**rf_params)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, rf_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting 모델의 하이퍼파라미터 탐색 공간과 목적 함수 정의\n",
    "def gb_objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=100)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    gb = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                   max_depth=max_depth, random_state=42)\n",
    "    score = cross_val_score(gb, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    rmse = (-1 * score.mean()) ** 0.5\n",
    "    return rmse\n",
    "\n",
    "# Gradient Boosting 모델의 하이퍼파라미터 최적화\n",
    "gb_params = optimize_model(gb_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼 파라미터 적용 후 학습 및 예측\n",
    "gb.set_params(**gb_params)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_y_pred = gb.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, gb_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(gb, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 모델의 하이퍼파라미터 탐색 공간과 목적 함수 정의\n",
    "def xgb_objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=100)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1)\n",
    "    xgb = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                       max_depth=max_depth, subsample=subsample, random_state=42)\n",
    "    score = cross_val_score(xgb, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    rmse = (-1 * score.mean()) ** 0.5\n",
    "    return rmse\n",
    "    \n",
    "# XGBoost 모델의 하이퍼파라미터 최적화\n",
    "xgb_params = optimize_model(xgb_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼 파라미터 적용 후 학습 및 예측\n",
    "xgb.set_params(**xgb_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, xgb_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, xgb_y_pred)\n",
    "r2 = r2_score(y_test, xgb_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(xgb, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 모델의 하이퍼파라미터 탐색 공간과 목적 함수 정의\n",
    "def lgbm_objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=100)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 10, 100)\n",
    "    lgbm = LGBMRegressor(n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "    max_depth=max_depth, num_leaves=num_leaves, random_state=42)\n",
    "    score = cross_val_score(lgbm, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    rmse = (-1 * score.mean()) ** 0.5\n",
    "    return rmse\n",
    "\n",
    "# LightGBM 모델의 하이퍼파라미터 최적화\n",
    "lgbm_params = optimize_model(lgbm_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼 파라미터 적용 후 학습 및 예측\n",
    "lgbm.set_params(**lgbm_params)\n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_y_pred = lgbm.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, lgbm_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, lgbm_y_pred)\n",
    "r2 = r2_score(y_test, lgbm_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(lgbm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees Regressor 모델의 하이퍼파라미터 탐색 공간과 목적 함수 정의\n",
    "def et_objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=100)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    et = ExtraTreesRegressor(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                             min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                             random_state=42)\n",
    "    score = cross_val_score(et, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    rmse = (-1 * score.mean()) ** 0.5\n",
    "    return rmse\n",
    "\n",
    "# Extra Trees Regressor 모델의 하이퍼파라미터 최적화\n",
    "et_params = optimize_model(et_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼 파라미터 적용 후 학습 및 예측\n",
    "et.set_params(**et_params)\n",
    "et.fit(X_train, y_train)\n",
    "et_y_pred = et.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, et_y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, et_y_pred)\n",
    "r2 = r2_score(y_test, et_y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(et, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타 모델 선정\n",
    "models = [rf, gb, xgb, lgbm, et]\n",
    "best_score = float(\"-inf\")\n",
    "best_model = None\n",
    "\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    rmse = (-1 * score.mean()) ** 0.5\n",
    "    if rmse > best_score:\n",
    "        best_score = rmse\n",
    "        best_model = model\n",
    "\n",
    "print(\"best_model :\", best_model)\n",
    "\n",
    "# 앙상블 모델 정의\n",
    "stack = StackingCVRegressor(regressors=(rf, gb, xgb, lgbm, et),\n",
    "                            meta_regressor=best_model,\n",
    "                            cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                            use_features_in_secondary=True)\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# 앙상블 모델 예측\n",
    "y_pred = stack.predict(X_test)\n",
    "\n",
    "# 평가지표 계산\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 평가지표 출력\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 그리기\n",
    "plot_learning_curve(stack, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
